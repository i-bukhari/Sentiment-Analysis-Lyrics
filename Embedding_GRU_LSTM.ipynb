{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/i-bukhari/Sentiment-Analysis-Lyrics/blob/main/Embedding_GRU_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates the implementation of a sentiment analysis model on song lyrics using a combination of Word Embeddings, Gated Recurrent Unit (GRU), and Long short-term memory (LSTM) architectures. It includes data preprocessing steps, model training, and evaluation to classify the lyrics as positive or negative based on valence scores."
      ],
      "metadata": {
        "id": "0qKjv_aOUlGo"
      },
      "id": "0qKjv_aOUlGo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "Q73j-jVnEnQR"
      },
      "id": "Q73j-jVnEnQR"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGsEYi-aYMPe",
        "outputId": "ed0dcc6b-2963-4067-cda1-23f47f508964"
      },
      "id": "nGsEYi-aYMPe",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=4a5b09d2228c3946c0f4b57aefb26034648acc8334e97aff34b55faa6bd26085\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langdetect import detect\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, GRU\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "8PlRFHRP82h1"
      },
      "id": "8PlRFHRP82h1",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "BTqvrsrSEtGV"
      },
      "id": "BTqvrsrSEtGV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Removing Empty Lyrics and Non-english Lyrics"
      ],
      "metadata": {
        "id": "YRJz-2b7YobK"
      },
      "id": "YRJz-2b7YobK"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f838dd34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f838dd34",
        "outputId": "b5c487c3-6de5-43d9-ab86-b1697cbcf19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-3b315841332d>:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['positivity'] = data['valence_tags'].apply(positivity)\n"
          ]
        }
      ],
      "source": [
        "def is_english(text):\n",
        "    try:\n",
        "        lang = detect(text)\n",
        "        return lang == 'en'\n",
        "    except:\n",
        "\n",
        "        return False\n",
        "def lang(text):\n",
        "    if is_english(text):\n",
        "        return 1\n",
        "    else:\n",
        "        return\n",
        "def positivity(valence_score): #9-point scale valence score\n",
        "        if valence_score<=4.5:\n",
        "            return 0\n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "original_df = pd.read_csv('muse_v3_with_lyrics_filled.csv') #upload csv manually, data scraped and extracted into csv\n",
        "data = original_df[['lyric','valence_tags']]\n",
        "data = data.dropna(subset=['lyric'])\n",
        "data['lang'] = data['lyric'].apply(lang)\n",
        "data = data.dropna(subset=['lang'])\n",
        "data['positivity'] = data['valence_tags'].apply(positivity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6faccd7e",
      "metadata": {
        "id": "6faccd7e"
      },
      "outputs": [],
      "source": [
        "def modify_sent(input_string):\n",
        "    lines = input_string.split('\\n')\n",
        "    output_string = '. '.join(lines)\n",
        "    return output_string\n",
        "\n",
        "data['lyrics'] = data['lyric'].apply(modify_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "33acc474",
      "metadata": {
        "id": "33acc474"
      },
      "outputs": [],
      "source": [
        "###### BALANCE DATA #######\n",
        "\n",
        "negative_data = data[data['positivity'] == 0]\n",
        "num_negative = len(negative_data)\n",
        "\n",
        "positive_data = data[data['positivity'] == 1]\n",
        "positive_sampled = positive_data.sample(n=num_negative, replace=False, random_state=42)\n",
        "\n",
        "balanced_data = pd.concat([negative_data, positive_sampled])\n",
        "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "balanced_data = balanced_data.drop(columns=['lyric','lang'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b19b3e7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "b19b3e7e",
        "outputId": "8a092938-5e2d-492f-c8aa-d0abc0f16ca7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       valence_tags  positivity  \\\n",
              "0          6.184659           1   \n",
              "1          1.964286           0   \n",
              "2          7.012289           1   \n",
              "3          2.513333           0   \n",
              "4          5.802817           1   \n",
              "...             ...         ...   \n",
              "16845      6.843000           1   \n",
              "16846      7.345556           1   \n",
              "16847      3.940000           0   \n",
              "16848      2.530000           0   \n",
              "16849      5.525000           1   \n",
              "\n",
              "                                                  lyrics  \n",
              "0      If I could make a wish, I think I'd pass. Can'...  \n",
              "1      Magician, magician, take me upon your wings. A...  \n",
              "2      [Verse 1]. You wanna know if I know why?. I ca...  \n",
              "3      Yes I've been waiting, but you just don't come...  \n",
              "4      [Intro]. Mmmh, pacify. Mmmh, pacify. Mmmh. Cla...  \n",
              "...                                                  ...  \n",
              "16845  [Verse 1]. After all these implements and text...  \n",
              "16846  [Intro]. Oh, ooh. Erica Kane. . [Verse 1]. She...  \n",
              "16847  Open the lid of the chest of Man. Let the drea...  \n",
              "16848  Close your eyes, we're coming down. Close your...  \n",
              "16849  Spread your wild seed on fertile ground. Plug ...  \n",
              "\n",
              "[16850 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4661a48-dfc5-476d-8ea3-b6534ce2398e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>valence_tags</th>\n",
              "      <th>positivity</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.184659</td>\n",
              "      <td>1</td>\n",
              "      <td>If I could make a wish, I think I'd pass. Can'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.964286</td>\n",
              "      <td>0</td>\n",
              "      <td>Magician, magician, take me upon your wings. A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.012289</td>\n",
              "      <td>1</td>\n",
              "      <td>[Verse 1]. You wanna know if I know why?. I ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.513333</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes I've been waiting, but you just don't come...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.802817</td>\n",
              "      <td>1</td>\n",
              "      <td>[Intro]. Mmmh, pacify. Mmmh, pacify. Mmmh. Cla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16845</th>\n",
              "      <td>6.843000</td>\n",
              "      <td>1</td>\n",
              "      <td>[Verse 1]. After all these implements and text...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16846</th>\n",
              "      <td>7.345556</td>\n",
              "      <td>1</td>\n",
              "      <td>[Intro]. Oh, ooh. Erica Kane. . [Verse 1]. She...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16847</th>\n",
              "      <td>3.940000</td>\n",
              "      <td>0</td>\n",
              "      <td>Open the lid of the chest of Man. Let the drea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16848</th>\n",
              "      <td>2.530000</td>\n",
              "      <td>0</td>\n",
              "      <td>Close your eyes, we're coming down. Close your...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16849</th>\n",
              "      <td>5.525000</td>\n",
              "      <td>1</td>\n",
              "      <td>Spread your wild seed on fertile ground. Plug ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16850 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4661a48-dfc5-476d-8ea3-b6534ce2398e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a4661a48-dfc5-476d-8ea3-b6534ce2398e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a4661a48-dfc5-476d-8ea3-b6534ce2398e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1763c19f-bca1-4ffa-9de8-3fba48ce822d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1763c19f-bca1-4ffa-9de8-3fba48ce822d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1763c19f-bca1-4ffa-9de8-3fba48ce822d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_99436dc2-5923-4685-bcc2-03520f166d38\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('balanced_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_99436dc2-5923-4685-bcc2-03520f166d38 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('balanced_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "balanced_data",
              "summary": "{\n  \"name\": \"balanced_data\",\n  \"rows\": 16850,\n  \"fields\": [\n    {\n      \"column\": \"valence_tags\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.668597976508972,\n        \"min\": 0.235,\n        \"max\": 8.47,\n        \"num_unique_values\": 8615,\n        \"samples\": [\n          3.67,\n          3.686071429,\n          7.591428571\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lyrics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16845,\n        \"samples\": [\n          \"Ouch, there is pain inside of me. Too sick to sigh. I'll just lie awake. Don't have to try. Just take what becomes of it. Ouch, I'll take it anyway. When the days grow old. And the mountains tired. I sing to my-self. The volcano cries. Ouch, the pain I'm tired of it. But who am I. To take up all the blame. Look for reasons why. But nothing becomes of it. Ouch the pain won't go away. Who the hell do you think you are. Like I got nothing better to do. Than sit around and think of you. Do you know how it feels to be lonely. And be in love and be no one at all\",\n          \"Evening is unreal. When morning leaves the moon. Approaching most in tears. He dances draped and new. Armed with many warnings. We face the ancient mold. If God and battles over. Just one of many roads. . Forgotten dream. Peace will come and with it sleep. I clear my mind. Peace will come and with it sleep. Forgotten dreams. I clear my mind and. Peace will come and with it sleep. Forgotten dream. Peace will come and with it sleep. I clear my mind. Peace will come and with it sleep. Forgotten dream. I clear my mind. Peace will come and with it sleep\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "balanced_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lyric_sentiment(lyrics):\n",
        "  sentence = lyrics.split(\". \")\n",
        "\n",
        "  score = []\n",
        "  threshold = 0\n",
        "\n",
        "  for i in sentence:\n",
        "    score.append(TextBlob(i).sentiment.polarity)\n",
        "\n",
        "  important_score = [i for i in score if i!=0]\n",
        "\n",
        "  if np.mean(important_score) > threshold :\n",
        "    return 1\n",
        "\n",
        "  else :\n",
        "    return 0"
      ],
      "metadata": {
        "id": "e0_6R_UVq_xk"
      },
      "id": "e0_6R_UVq_xk",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy_b = balanced_data.copy()\n",
        "df_copy_b['polarity'] = df_copy_b['lyrics'].apply(lyric_sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCpOxezbr9f-",
        "outputId": "c10b195d-e34d-4e5b-8f4d-0b4b7142feb0"
      },
      "id": "ZCpOxezbr9f-",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PfyDWh2qsEi9",
        "outputId": "e66c4c48-14fb-4a3a-f3d1-da5746cdfbaa"
      },
      "id": "PfyDWh2qsEi9",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       valence_tags  positivity  \\\n",
              "0          6.184659           1   \n",
              "1          1.964286           0   \n",
              "2          7.012289           1   \n",
              "3          2.513333           0   \n",
              "4          5.802817           1   \n",
              "...             ...         ...   \n",
              "16845      6.843000           1   \n",
              "16846      7.345556           1   \n",
              "16847      3.940000           0   \n",
              "16848      2.530000           0   \n",
              "16849      5.525000           1   \n",
              "\n",
              "                                                  lyrics  polarity  \n",
              "0      If I could make a wish, I think I'd pass. Can'...         1  \n",
              "1      Magician, magician, take me upon your wings. A...         1  \n",
              "2      [Verse 1]. You wanna know if I know why?. I ca...         0  \n",
              "3      Yes I've been waiting, but you just don't come...         1  \n",
              "4      [Intro]. Mmmh, pacify. Mmmh, pacify. Mmmh. Cla...         1  \n",
              "...                                                  ...       ...  \n",
              "16845  [Verse 1]. After all these implements and text...         0  \n",
              "16846  [Intro]. Oh, ooh. Erica Kane. . [Verse 1]. She...         0  \n",
              "16847  Open the lid of the chest of Man. Let the drea...         0  \n",
              "16848  Close your eyes, we're coming down. Close your...         0  \n",
              "16849  Spread your wild seed on fertile ground. Plug ...         1  \n",
              "\n",
              "[16850 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf100945-56f2-49ca-a1d1-2b97f9a397e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>valence_tags</th>\n",
              "      <th>positivity</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.184659</td>\n",
              "      <td>1</td>\n",
              "      <td>If I could make a wish, I think I'd pass. Can'...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.964286</td>\n",
              "      <td>0</td>\n",
              "      <td>Magician, magician, take me upon your wings. A...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.012289</td>\n",
              "      <td>1</td>\n",
              "      <td>[Verse 1]. You wanna know if I know why?. I ca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.513333</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes I've been waiting, but you just don't come...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.802817</td>\n",
              "      <td>1</td>\n",
              "      <td>[Intro]. Mmmh, pacify. Mmmh, pacify. Mmmh. Cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16845</th>\n",
              "      <td>6.843000</td>\n",
              "      <td>1</td>\n",
              "      <td>[Verse 1]. After all these implements and text...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16846</th>\n",
              "      <td>7.345556</td>\n",
              "      <td>1</td>\n",
              "      <td>[Intro]. Oh, ooh. Erica Kane. . [Verse 1]. She...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16847</th>\n",
              "      <td>3.940000</td>\n",
              "      <td>0</td>\n",
              "      <td>Open the lid of the chest of Man. Let the drea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16848</th>\n",
              "      <td>2.530000</td>\n",
              "      <td>0</td>\n",
              "      <td>Close your eyes, we're coming down. Close your...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16849</th>\n",
              "      <td>5.525000</td>\n",
              "      <td>1</td>\n",
              "      <td>Spread your wild seed on fertile ground. Plug ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16850 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf100945-56f2-49ca-a1d1-2b97f9a397e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf100945-56f2-49ca-a1d1-2b97f9a397e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf100945-56f2-49ca-a1d1-2b97f9a397e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-10d8916e-de70-4829-8637-fb5c1607673d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10d8916e-de70-4829-8637-fb5c1607673d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-10d8916e-de70-4829-8637-fb5c1607673d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a3442040-dfb2-4f47-99d4-e2577be99069\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_copy_b')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a3442040-dfb2-4f47-99d4-e2577be99069 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_copy_b');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_copy_b",
              "summary": "{\n  \"name\": \"df_copy_b\",\n  \"rows\": 16850,\n  \"fields\": [\n    {\n      \"column\": \"valence_tags\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.668597976508972,\n        \"min\": 0.235,\n        \"max\": 8.47,\n        \"num_unique_values\": 8615,\n        \"samples\": [\n          3.67,\n          3.686071429,\n          7.591428571\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lyrics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16845,\n        \"samples\": [\n          \"Ouch, there is pain inside of me. Too sick to sigh. I'll just lie awake. Don't have to try. Just take what becomes of it. Ouch, I'll take it anyway. When the days grow old. And the mountains tired. I sing to my-self. The volcano cries. Ouch, the pain I'm tired of it. But who am I. To take up all the blame. Look for reasons why. But nothing becomes of it. Ouch the pain won't go away. Who the hell do you think you are. Like I got nothing better to do. Than sit around and think of you. Do you know how it feels to be lonely. And be in love and be no one at all\",\n          \"Evening is unreal. When morning leaves the moon. Approaching most in tears. He dances draped and new. Armed with many warnings. We face the ancient mold. If God and battles over. Just one of many roads. . Forgotten dream. Peace will come and with it sleep. I clear my mind. Peace will come and with it sleep. Forgotten dreams. I clear my mind and. Peace will come and with it sleep. Forgotten dream. Peace will come and with it sleep. I clear my mind. Peace will come and with it sleep. Forgotten dream. I clear my mind. Peace will come and with it sleep\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model analysis based on \"Positivity\" score"
      ],
      "metadata": {
        "id": "onD0uCpGUuO4"
      },
      "id": "onD0uCpGUuO4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Positivity\" score extracted from \"Valenence Tags\" and Song Lyrics"
      ],
      "metadata": {
        "id": "-56-m7x0VAjn"
      },
      "id": "-56-m7x0VAjn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "V6PbE1oe6VkZ"
      },
      "id": "V6PbE1oe6VkZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKVtV_Rm6XOS",
        "outputId": "7924fd5e-bfb0-4827-db25-cc7e822c939d"
      },
      "id": "XKVtV_Rm6XOS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word.isalpha()]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "balanced_data['processed_lyrics'] = balanced_data['lyrics'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "sU1hQyob6Zh4"
      },
      "id": "sU1hQyob6Zh4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing the text with new parameters\n",
        "tfidf = TfidfVectorizer(max_df=0.7, min_df=5, ngram_range=(1, 2))\n",
        "X_tfidf = tfidf.fit_transform(balanced_data['processed_lyrics'])"
      ],
      "metadata": {
        "id": "iOZQRzrU6bdZ"
      },
      "id": "iOZQRzrU6bdZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest + TFIDF"
      ],
      "metadata": {
        "id": "shYV3IKTCVQq"
      },
      "id": "shYV3IKTCVQq"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, balanced_data['positivity'], test_size=0.3, random_state=42)\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Drb7GozI6ePA",
        "outputId": "8eb31d48-4dfc-424f-d866-ed2a9aab722d"
      },
      "id": "Drb7GozI6ePA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.62      0.61      2554\n",
            "           1       0.60      0.58      0.59      2500\n",
            "\n",
            "    accuracy                           0.60      5054\n",
            "   macro avg       0.60      0.60      0.60      5054\n",
            "weighted avg       0.60      0.60      0.60      5054\n",
            "\n",
            "Accuracy Score: 0.5989315393747526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GloVe Embedding"
      ],
      "metadata": {
        "id": "gi6o-FKl7JfJ"
      },
      "id": "gi6o-FKl7JfJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "sofNzrjX8Jkg"
      },
      "id": "sofNzrjX8Jkg"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(path):\n",
        "    embeddings_dict = {}\n",
        "    with open(path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], \"float32\")\n",
        "            embeddings_dict[word] = vector\n",
        "    return embeddings_dict\n",
        "\n",
        "glove_embeddings = load_glove_embeddings('glove.6B.300d.txt')\n",
        "\n",
        "def text_to_mean_vector(text, embeddings):\n",
        "    words = word_tokenize(text.lower())\n",
        "    vectors = [embeddings.get(word, np.zeros(300)) for word in words]  # Adjusted the dimension to 300\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(300)\n",
        "\n",
        "\n",
        "if 'processed_lyrics' not in balanced_data.columns:\n",
        "    print(\"Error: 'processed_lyrics' column is missing\")\n",
        "else:\n",
        "\n",
        "    balanced_data['mean_embedding'] = balanced_data['processed_lyrics'].apply(lambda x: text_to_mean_vector(x, glove_embeddings))\n",
        "\n",
        "    if balanced_data['mean_embedding'].isnull().any():\n",
        "        print(\"Error: Missing embeddings in data\")\n",
        "    if 'positivity' not in balanced_data.columns:\n",
        "        print(\"Error: 'positivity' labels are missing\")\n",
        "    else:\n",
        "        X = np.array(balanced_data['mean_embedding'].tolist())\n",
        "        y = balanced_data['positivity'].values\n",
        "\n",
        "        print(\"Length of X:\", len(X))\n",
        "        print(\"Length of y:\", len(y))\n",
        "\n",
        "        if len(X) == len(y):\n",
        "\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "            rf_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "            y_pred = rf_model.predict(X_test)\n",
        "            report = classification_report(y_test, y_pred, target_names=['Negative', 'Positive'])\n",
        "            print(\"Classification Report with Random Forest and GloVe Embeddings: \\n\", report)\n",
        "        else:\n",
        "            print(\"Error: The lengths of X and y do not match.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0iJIogQ8LLw",
        "outputId": "5c9a4eca-4531-4e28-9cd5-7ba3a9f31e1c"
      },
      "id": "w0iJIogQ8LLw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of X: 16844\n",
            "Length of y: 16844\n",
            "Classification Report with Random Forest and GloVe Embeddings: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.58      0.61      0.60      1688\n",
            "    Positive       0.59      0.56      0.58      1681\n",
            "\n",
            "    accuracy                           0.59      3369\n",
            "   macro avg       0.59      0.59      0.59      3369\n",
            "weighted avg       0.59      0.59      0.59      3369\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM + GloVe Embeddings"
      ],
      "metadata": {
        "id": "OU8iPN4XHuoU"
      },
      "id": "OU8iPN4XHuoU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Learning Rate = 0.001"
      ],
      "metadata": {
        "id": "c1ziu2pMSLYM"
      },
      "id": "c1ziu2pMSLYM"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove_embeddings(path):\n",
        "    embeddings_dict = {}\n",
        "    with open(path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], \"float32\")\n",
        "            embeddings_dict[word] = vector\n",
        "    return embeddings_dict\n",
        "\n",
        "\n",
        "glove_embeddings = load_glove_embeddings('glove.6B.300d.txt')\n",
        "\n",
        "\n",
        "vocab_size = 10000  # Adjust as per your vocabulary\n",
        "embedding_dim = 300  # GloVe vectors dimension\n",
        "max_length = 100    # Length of each input sequence\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(balanced_data['lyrics'])\n",
        "\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(balanced_data['lyrics'])\n",
        "\n",
        "\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
        "\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < vocab_size:\n",
        "        embedding_vector = glove_embeddings.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "\n",
        "learning_rate = 0.001  # Change as needed\n",
        "\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, embeddings_initializer=Constant(embedding_matrix), input_length=max_length, trainable=False))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, embeddings_initializer=Constant(embedding_matrix), input_length=max_length, trainable=False))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "labels = balanced_data['positivity'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsOmhv_nHxEG",
        "outputId": "cd64be96-e6ba-4d54-9d1c-f171735164c4"
      },
      "id": "TsOmhv_nHxEG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "211/211 [==============================] - 54s 245ms/step - loss: 0.6872 - accuracy: 0.5443 - val_loss: 0.6835 - val_accuracy: 0.5491\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 53s 249ms/step - loss: 0.6723 - accuracy: 0.5852 - val_loss: 0.6699 - val_accuracy: 0.5859\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 52s 246ms/step - loss: 0.6585 - accuracy: 0.6032 - val_loss: 0.6700 - val_accuracy: 0.5954\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 54s 257ms/step - loss: 0.6405 - accuracy: 0.6245 - val_loss: 0.6726 - val_accuracy: 0.5951\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 53s 250ms/step - loss: 0.6153 - accuracy: 0.6511 - val_loss: 0.6919 - val_accuracy: 0.5821\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 52s 245ms/step - loss: 0.5721 - accuracy: 0.6907 - val_loss: 0.7342 - val_accuracy: 0.5690\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 53s 250ms/step - loss: 0.5099 - accuracy: 0.7380 - val_loss: 0.8303 - val_accuracy: 0.5708\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 53s 250ms/step - loss: 0.4316 - accuracy: 0.7864 - val_loss: 0.9473 - val_accuracy: 0.5723\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 52s 245ms/step - loss: 0.3397 - accuracy: 0.8457 - val_loss: 1.1102 - val_accuracy: 0.5726\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 53s 250ms/step - loss: 0.2601 - accuracy: 0.8847 - val_loss: 1.2441 - val_accuracy: 0.5539\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f5f143ce320>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = (y_pred_probs > 0.5).astype('int32')\n",
        "\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "# Calculate F1 score and print classification report\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "report = classification_report(y_test, y_pred, target_names=['Negative', 'Positive'])\n",
        "print(\"Detailed Classification Report: \\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAFV-3pLH0vJ",
        "outputId": "1f685ff1-6650-4de8-829a-aacabc9709a2"
      },
      "id": "cAFV-3pLH0vJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 8s 74ms/step - loss: 1.2441 - accuracy: 0.5539\n",
            "Test Accuracy: 55.39%\n",
            "106/106 [==============================] - 8s 73ms/step\n",
            "F1 Score: 0.55\n",
            "Detailed Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.55      0.56      0.56      1688\n",
            "    Positive       0.55      0.55      0.55      1681\n",
            "\n",
            "    accuracy                           0.55      3369\n",
            "   macro avg       0.55      0.55      0.55      3369\n",
            "weighted avg       0.55      0.55      0.55      3369\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Learning Rate = 0.01"
      ],
      "metadata": {
        "id": "dg0QThP1SPIO"
      },
      "id": "dg0QThP1SPIO"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(path):\n",
        "    embeddings_dict = {}\n",
        "    with open(path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], \"float32\")\n",
        "            embeddings_dict[word] = vector\n",
        "    return embeddings_dict\n",
        "\n",
        "glove_embeddings = load_glove_embeddings('glove.6B.300d.txt')\n",
        "\n",
        "vocab_size = 10000  # Adjust as per your vocabulary\n",
        "embedding_dim = 300  # GloVe vectors dimension\n",
        "max_length = 100    # Length of each input sequence\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(balanced_data['lyrics'])\n",
        "\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(balanced_data['lyrics'])\n",
        "\n",
        "\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
        "\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < vocab_size:\n",
        "        embedding_vector = glove_embeddings.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "\n",
        "\n",
        "learning_rate = 0.01  # Change as needed\n",
        "\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Model architecture remains the same\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, embeddings_initializer=Constant(embedding_matrix), input_length=max_length, trainable=False))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "labels = balanced_data['positivity'].values\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIZENS-PRmmf",
        "outputId": "20132331-0de9-4ff9-b431-60350b528289"
      },
      "id": "BIZENS-PRmmf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "211/211 [==============================] - 65s 290ms/step - loss: 0.6848 - accuracy: 0.5525 - val_loss: 0.6693 - val_accuracy: 0.5859\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 58s 275ms/step - loss: 0.6723 - accuracy: 0.5786 - val_loss: 0.6740 - val_accuracy: 0.5809\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 58s 273ms/step - loss: 0.6586 - accuracy: 0.6039 - val_loss: 0.6768 - val_accuracy: 0.5788\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 57s 271ms/step - loss: 0.6421 - accuracy: 0.6247 - val_loss: 0.6750 - val_accuracy: 0.5880\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 57s 271ms/step - loss: 0.6163 - accuracy: 0.6530 - val_loss: 0.6939 - val_accuracy: 0.5687\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 57s 269ms/step - loss: 0.5779 - accuracy: 0.6822 - val_loss: 0.7375 - val_accuracy: 0.5723\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 58s 277ms/step - loss: 0.5241 - accuracy: 0.7291 - val_loss: 0.7873 - val_accuracy: 0.5637\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 58s 273ms/step - loss: 0.4450 - accuracy: 0.7810 - val_loss: 0.8994 - val_accuracy: 0.5571\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 59s 279ms/step - loss: 0.3678 - accuracy: 0.8244 - val_loss: 1.0214 - val_accuracy: 0.5459\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 60s 283ms/step - loss: 0.2862 - accuracy: 0.8740 - val_loss: 1.2803 - val_accuracy: 0.5592\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f5f20ccbe20>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = (y_pred_probs > 0.5).astype('int32')\n",
        "\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "report = classification_report(y_test, y_pred, target_names=['Negative', 'Positive'])\n",
        "print(\"Detailed Classification Report: \\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzhSgx_ARp1m",
        "outputId": "62a6ca51-faf5-484d-8ab0-b2b678a5ddb3"
      },
      "id": "BzhSgx_ARp1m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 10s 91ms/step - loss: 1.2803 - accuracy: 0.5592\n",
            "Test Accuracy: 55.92%\n",
            "106/106 [==============================] - 10s 86ms/step\n",
            "F1 Score: 0.56\n",
            "Detailed Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.56      0.55      0.56      1688\n",
            "    Positive       0.56      0.57      0.56      1681\n",
            "\n",
            "    accuracy                           0.56      3369\n",
            "   macro avg       0.56      0.56      0.56      3369\n",
            "weighted avg       0.56      0.56      0.56      3369\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression + GloVe Embeddings"
      ],
      "metadata": {
        "id": "l_OAG8xdH7Vg"
      },
      "id": "l_OAG8xdH7Vg"
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_mean_vector(text, embeddings):\n",
        "    words = word_tokenize(text.lower())\n",
        "    vectors = [embeddings.get(word, np.zeros(300)) for word in words]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(300)\n",
        "\n",
        "if 'processed_lyrics' not in balanced_data.columns:\n",
        "    print(\"Error: 'processed_lyrics' column is missing\")\n",
        "else:\n",
        "    balanced_data['mean_embedding'] = balanced_data['processed_lyrics'].apply(lambda x: text_to_mean_vector(x, glove_embeddings))\n",
        "\n",
        "    if balanced_data['mean_embedding'].isnull().any():\n",
        "        print(\"Error: Missing embeddings in data\")\n",
        "    if 'positivity' not in balanced_data.columns:\n",
        "        print(\"Error: 'positivity' labels are missing\")\n",
        "    else:\n",
        "        X = np.array(balanced_data['mean_embedding'].tolist())\n",
        "        y = balanced_data['positivity'].values\n",
        "\n",
        "        print(\"Length of X:\", len(X))\n",
        "        print(\"Length of y:\", len(y))\n",
        "\n",
        "        if len(X) == len(y):\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            log_reg_model = LogisticRegression(max_iter=1000)\n",
        "            log_reg_model.fit(X_train, y_train)\n",
        "\n",
        "            y_pred = log_reg_model.predict(X_test)\n",
        "            report = classification_report(y_test, y_pred, target_names=['Negative', 'Positive'])\n",
        "            print(\"Classification Report with Logistic Regression and GloVe Embeddings: \\n\", report)\n",
        "        else:\n",
        "            print(\"Error: The lengths of X and y do not match.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XbTpdIFH-Zy",
        "outputId": "4f0abe00-2a41-4a85-f348-078f145f9e1c"
      },
      "id": "1XbTpdIFH-Zy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of X: 16844\n",
            "Length of y: 16844\n",
            "Classification Report with Logistic Regression and GloVe Embeddings: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.63      0.60      0.61      1688\n",
            "    Positive       0.61      0.65      0.63      1681\n",
            "\n",
            "    accuracy                           0.62      3369\n",
            "   macro avg       0.62      0.62      0.62      3369\n",
            "weighted avg       0.62      0.62      0.62      3369\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU Model  - Positivity"
      ],
      "metadata": {
        "id": "nviUUrxs93vO"
      },
      "id": "nviUUrxs93vO"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(path):\n",
        "    embeddings_dict = {}\n",
        "    with open(path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], \"float32\")\n",
        "            embeddings_dict[word] = vector\n",
        "    return embeddings_dict\n",
        "\n",
        "glove_embeddings = load_glove_embeddings('glove.6B.300d.txt')\n",
        "\n",
        "# Parameters\n",
        "vocab_size = 10000  # Choose based on your vocabulary size\n",
        "max_length = 100    # Length of each padded sequence\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(balanced_data['lyrics'])\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(balanced_data['lyrics']) # Convert texts to sequences\n",
        "\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
        "\n",
        "# Create an embedding matrix\n",
        "embedding_dim = 300  # Dimensionality of GloVe vectors\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < vocab_size:\n",
        "        embedding_vector = glove_embeddings.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# Model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, embeddings_initializer=Constant(embedding_matrix), input_length=max_length, trainable=False))\n",
        "model.add(GRU(128, return_sequences=True))  # GRU layer with 128 units\n",
        "model.add(GRU(128))  # Another GRU layer; adjust the number of units as necessary\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "labels = balanced_data['positivity'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5R5KTEQ945e",
        "outputId": "48453f3c-1500-4d26-f17b-6a2ec9d0a74f"
      },
      "id": "Z5R5KTEQ945e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 100, 300)          3000000   \n",
            "                                                                 \n",
            " gru_4 (GRU)                 (None, 100, 128)          165120    \n",
            "                                                                 \n",
            " gru_5 (GRU)                 (None, 128)               99072     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3264321 (12.45 MB)\n",
            "Trainable params: 264321 (1.01 MB)\n",
            "Non-trainable params: 3000000 (11.44 MB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "211/211 [==============================] - 47s 210ms/step - loss: 0.6905 - accuracy: 0.5291 - val_loss: 0.6834 - val_accuracy: 0.5506\n",
            "Epoch 2/20\n",
            "211/211 [==============================] - 45s 212ms/step - loss: 0.6751 - accuracy: 0.5765 - val_loss: 0.6753 - val_accuracy: 0.5770\n",
            "Epoch 3/20\n",
            "211/211 [==============================] - 44s 209ms/step - loss: 0.6571 - accuracy: 0.6024 - val_loss: 0.6777 - val_accuracy: 0.5815\n",
            "Epoch 4/20\n",
            "211/211 [==============================] - 43s 205ms/step - loss: 0.6398 - accuracy: 0.6322 - val_loss: 0.6896 - val_accuracy: 0.5827\n",
            "Epoch 5/20\n",
            "211/211 [==============================] - 44s 207ms/step - loss: 0.6130 - accuracy: 0.6610 - val_loss: 0.6962 - val_accuracy: 0.5699\n",
            "Epoch 6/20\n",
            "211/211 [==============================] - 44s 208ms/step - loss: 0.5640 - accuracy: 0.7006 - val_loss: 0.7452 - val_accuracy: 0.5613\n",
            "Epoch 7/20\n",
            "211/211 [==============================] - 44s 208ms/step - loss: 0.4846 - accuracy: 0.7593 - val_loss: 0.8388 - val_accuracy: 0.5574\n",
            "Epoch 8/20\n",
            "211/211 [==============================] - 43s 205ms/step - loss: 0.3794 - accuracy: 0.8245 - val_loss: 1.0388 - val_accuracy: 0.5506\n",
            "Epoch 9/20\n",
            "211/211 [==============================] - 43s 204ms/step - loss: 0.2647 - accuracy: 0.8882 - val_loss: 1.3197 - val_accuracy: 0.5530\n",
            "Epoch 10/20\n",
            "211/211 [==============================] - 43s 205ms/step - loss: 0.1686 - accuracy: 0.9311 - val_loss: 1.6070 - val_accuracy: 0.5453\n",
            "Epoch 11/20\n",
            "211/211 [==============================] - 42s 200ms/step - loss: 0.0981 - accuracy: 0.9625 - val_loss: 2.0222 - val_accuracy: 0.5417\n",
            "Epoch 12/20\n",
            "211/211 [==============================] - 42s 200ms/step - loss: 0.0630 - accuracy: 0.9793 - val_loss: 2.2143 - val_accuracy: 0.5456\n",
            "Epoch 13/20\n",
            "211/211 [==============================] - 43s 204ms/step - loss: 0.0399 - accuracy: 0.9877 - val_loss: 2.6832 - val_accuracy: 0.5447\n",
            "Epoch 14/20\n",
            "211/211 [==============================] - 42s 201ms/step - loss: 0.0312 - accuracy: 0.9914 - val_loss: 2.7157 - val_accuracy: 0.5367\n",
            "Epoch 15/20\n",
            "211/211 [==============================] - 44s 211ms/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 3.0181 - val_accuracy: 0.5423\n",
            "Epoch 16/20\n",
            "211/211 [==============================] - 46s 217ms/step - loss: 0.0392 - accuracy: 0.9863 - val_loss: 2.8623 - val_accuracy: 0.5441\n",
            "Epoch 17/20\n",
            "211/211 [==============================] - 46s 218ms/step - loss: 0.0270 - accuracy: 0.9918 - val_loss: 2.9369 - val_accuracy: 0.5453\n",
            "Epoch 18/20\n",
            "211/211 [==============================] - 47s 225ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 3.3247 - val_accuracy: 0.5378\n",
            "Epoch 19/20\n",
            "211/211 [==============================] - 48s 229ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 3.3797 - val_accuracy: 0.5447\n",
            "Epoch 20/20\n",
            "211/211 [==============================] - 51s 243ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 3.5744 - val_accuracy: 0.5470\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f5ec1edd330>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = (y_pred_probs > 0.5).astype('int32')  # Convert probabilities to binary labels\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)  # Default is binary F1\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Classification report\n",
        "report = classification_report(y_test, y_pred, target_names=['Negative', 'Positive'])\n",
        "print(\"Detailed Classification Report: \\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oB6y-1X904p",
        "outputId": "dc443fb8-462b-4938-b1a9-1b7f3e382a67"
      },
      "id": "_oB6y-1X904p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 6s 52ms/step - loss: 3.5744 - accuracy: 0.5470\n",
            "Test Accuracy: 54.70%\n",
            "106/106 [==============================] - 6s 50ms/step\n",
            "F1 Score: 0.53\n",
            "Detailed Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.54      0.59      0.57      1688\n",
            "    Positive       0.55      0.50      0.53      1681\n",
            "\n",
            "    accuracy                           0.55      3369\n",
            "   macro avg       0.55      0.55      0.55      3369\n",
            "weighted avg       0.55      0.55      0.55      3369\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Polararity from TextBlob"
      ],
      "metadata": {
        "id": "Nf2xcpniXgNp"
      },
      "id": "Nf2xcpniXgNp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GRU Model - Polarity"
      ],
      "metadata": {
        "id": "riAuP6HhXmLg"
      },
      "id": "riAuP6HhXmLg"
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000  # Choose based on your vocabulary size\n",
        "max_length = 100    # Length of each padded sequence\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(df_copy_b['lyrics'])\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(df_copy_b['lyrics'])\n",
        "\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length)"
      ],
      "metadata": {
        "id": "YYwJfaGCXiOr"
      },
      "id": "YYwJfaGCXiOr",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, embeddings_initializer=Constant(embedding_matrix), input_length=max_length, trainable=False))\n",
        "model.add(GRU(128, return_sequences=True))  # GRU layer with 128 units\n",
        "model.add(GRU(128))  # Another GRU layer; adjust the number of units as necessary\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "labels = df_copy_b['polarity'].values\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjpTjfqeXu5m",
        "outputId": "3abd7cb2-9868-4fd6-d840-6fbb796b8bba"
      },
      "id": "FjpTjfqeXu5m",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 300)          3000000   \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 100, 128)          165120    \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, 128)               99072     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3264321 (12.45 MB)\n",
            "Trainable params: 264321 (1.01 MB)\n",
            "Non-trainable params: 3000000 (11.44 MB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "211/211 [==============================] - 122s 552ms/step - loss: 0.6546 - accuracy: 0.6404 - val_loss: 0.6539 - val_accuracy: 0.6401\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 113s 533ms/step - loss: 0.6532 - accuracy: 0.6421 - val_loss: 0.6534 - val_accuracy: 0.6401\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 109s 516ms/step - loss: 0.6530 - accuracy: 0.6421 - val_loss: 0.6537 - val_accuracy: 0.6401\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 123s 582ms/step - loss: 0.6527 - accuracy: 0.6421 - val_loss: 0.6537 - val_accuracy: 0.6401\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 114s 541ms/step - loss: 0.6529 - accuracy: 0.6421 - val_loss: 0.6534 - val_accuracy: 0.6401\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 111s 526ms/step - loss: 0.6526 - accuracy: 0.6421 - val_loss: 0.6541 - val_accuracy: 0.6401\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 110s 522ms/step - loss: 0.6526 - accuracy: 0.6421 - val_loss: 0.6534 - val_accuracy: 0.6401\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 107s 506ms/step - loss: 0.6525 - accuracy: 0.6421 - val_loss: 0.6538 - val_accuracy: 0.6401\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 111s 526ms/step - loss: 0.6528 - accuracy: 0.6421 - val_loss: 0.6552 - val_accuracy: 0.6401\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 111s 526ms/step - loss: 0.6525 - accuracy: 0.6421 - val_loss: 0.6534 - val_accuracy: 0.6401\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fc227d95390>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4ffEkU6X7xz",
        "outputId": "17688955-99ad-4a43-b0a5-660f7102dcdd"
      },
      "id": "c4ffEkU6X7xz",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 12s 109ms/step - loss: 0.6534 - accuracy: 0.6401\n",
            "Test Accuracy: 64.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = (y_pred_probs > 0.5).astype('int32')  # Convert probabilities to binary labels\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "report = classification_report(y_test, y_pred, target_names=['Negative', 'Positive'])\n",
        "print(\"Detailed Classification Report: \\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPWGSHozX9ig",
        "outputId": "25371b67-bfb2-417c-df4a-84eee245820f"
      },
      "id": "UPWGSHozX9ig",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 8s 80ms/step\n",
            "F1 Score: 0.78\n",
            "Detailed Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.00      0.00      0.00      1213\n",
            "    Positive       0.64      1.00      0.78      2157\n",
            "\n",
            "    accuracy                           0.64      3370\n",
            "   macro avg       0.32      0.50      0.39      3370\n",
            "weighted avg       0.41      0.64      0.50      3370\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}